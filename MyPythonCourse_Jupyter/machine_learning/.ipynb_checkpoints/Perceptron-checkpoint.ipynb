{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron\n",
    "This is a simple implementation of a primitive single node Perceptron classifier algorithm. Although this algorithm is too simplistic to be used in any modern real-world machine learning application, it is still a useful starting point for anyone interested in beginning their journey in learning about more advanced machine learning algorithms. Much of what you learn here will be helpful in your further studies!\n",
    "\n",
    "- The Perceptron is a linear classifier. It will not classify input data correctly if the data is not linearly separable.\n",
    "- Gradient Descent is an iterative optimization algorithm to find the minima of a curve.\n",
    "- Stochastic Gradient Descent - See: https://en.wikipedia.org/wiki/Stochastic_gradient_descent\n",
    "- See: https://en.wikipedia.org/wiki/Perceptron\n",
    "- Iris data is used in this example: https://archive.ics.uci.edu/ml/datasets/Iris\n",
    "\n",
    "The Perceptron is a machine learning algorithm used to determine whether an input pattern belongs to one class or another. It is one of the earliest examples of a primitive artificial neural network and it provides a basic example that most commonly used modern neural networks are originally based on.\n",
    "\n",
    "The Perceptron algorithm is an example of a supervised learning algorithm, which means that learning makes use of  labeled training data. Examples of correct input-output pairs are provided to train a predictive model.\n",
    "\n",
    "The Perceptron algorithm is a binary classifier, which means that it takes multiple input signals that represent data features and produces an output signal that indicates whether that input belongs to a particular class or pattern of input data.\n",
    "\n",
    "The Perceptron algorithm is a linear classifier, which means that it classifies data input patterns using a linear combination of the input data. It takes input data with the associated class membership label, and generates a linear model as a hyperplane that separates data of one class from data of other classes on either side of the resulting hyperplane. For this reason, a Single-layer Perceptron can only deal with input data that represents linearly separable classes. More complex class boundaries require Multiple-layer implementations.\n",
    "\n",
    "The Single-layer perceptron algorithm does not terminate if the training data set is not linearly separable. If the input vectors are not linearly separable then training will never reach a point where all vectors are classified correctly. In some cases, a Multi-layer Perceptron can correctly distinguish input data that is not linearly separable.\n",
    "\n",
    "Given an input with $k$ variables $x_1,x_2,...,x_k$, a hyperplane is a liner combination of these variables plus a scalar bias term $w_0$:\n",
    "\n",
    "$$w_0+w_1x_1+w_2x_2+...+w_kx_k=0 \\text{, where } w_0,w_1,...,w_k \\text{ are constants, and } w_0 \\text{ is a constant bias term}$$  \n",
    "The sum can be represented more compactly as:  \n",
    "\n",
    "$$\n",
    "sum=w_0+\\sum_{i=1}^k w_ix_i \\text{, where } k \\text{ is the number of inputs to the perceptron, and } w_0 \\text{ is the bias term}\n",
    "$$\n",
    "\n",
    "Then the output of the Perceptron is defined by the following activation function:\n",
    "\n",
    "$$\n",
    "f(sum) = \n",
    "\\begin{cases}\n",
    "  1 & \\text{if }sum>0\\\\\n",
    "  0 & \\text{otherwise}\\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Here is a pictorial representation of a single node Perceptron:\n",
    "\n",
    "![Perceptron](images/Perceptron.png \"Perceptron\")\n",
    "\n",
    "Here are the Perceptron training steps:\n",
    "1. A small learning rate $\\alpha$ is chosen.\n",
    "2. Initialize all elements in the vector $w$ to zero (including $w_0$ that represents the scalar bias value $b$).\n",
    "3. For each input vector $x$, determine whether $w\\cdot x\\gt0$. If it is, the activation function predicts 1, else it predicts 0.\n",
    "4. The value $b$ and the weights $w$ are updated in a nested inner loop: $b_{n+1}=b_{n}+\\alpha(label-prediction)$ and $w_{n+1}=w_{n}+\\alpha(label-prediction)x$.\n",
    "5. Repeat the outer loop sufficiently to get an effective working model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, num_inputs, learning_rate=0.01, max_steps=100):\n",
    "        self.max_steps = max_steps\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weights = np.zeros(num_inputs + 1) # 1D numpy.ndarray of zero floats\n",
    "        print(self.weights)\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        # activation = bias + sum(weight_i * x_i)\n",
    "        sum = self.weights[0] + np.dot(self.weights[1:], inputs)\n",
    "        # activation function\n",
    "        if sum > 0.0:\n",
    "            output = 1.0\n",
    "        else:\n",
    "            output = 0.0\n",
    "        return output\n",
    "\n",
    "    def train(self, training_inputs, labels):\n",
    "        for _ in range(self.max_steps):\n",
    "            num_no_zero_errors = 0\n",
    "            for inputs, label in zip(training_inputs, labels):\n",
    "                prediction = self.predict(inputs)\n",
    "                error = label - prediction\n",
    "                if error != 0:\n",
    "                    num_no_zero_errors += 1\n",
    "                # update bias b and weights w\n",
    "                self.weights[0] += self.learning_rate * error # bias term\n",
    "                self.weights[1:] += self.learning_rate * error * inputs # input terms\n",
    "            print(\"* num_no_zero_errors: \", num_no_zero_errors)\n",
    "            if num_no_zero_errors == 0:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15fa19cb400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "x_index = 0 # index of sepal length feature\n",
    "y_index = 1 # index of sepal width feature\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "for target in set(iris.target):\n",
    "    x = [iris.data[i,x_index] for i in range(len(iris.target)) if iris.target[i]==target]\n",
    "    y = [iris.data[i,y_index] for i in range(len(iris.target)) if iris.target[i]==target]\n",
    "    plt.scatter(x, y, color=['red', 'blue', 'green'][target], label=iris.target_names[target])\n",
    "plt.xlabel(iris.feature_names[x_index])\n",
    "plt.ylabel(iris.feature_names[y_index])\n",
    "plt.title('Iris Dataset')\n",
    "plt.legend(iris.target_names, loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data', 'target', 'target_names', 'DESCR', 'feature_names']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.data # sepal length, sepal width, petal length, petal width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target # 0 for setosa, 1 for versicolor, and 2 for virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data   # inputs  (150x4 numpy.ndarray of float64)\n",
    "y = iris.target # outputs (150 numpy.ndarray of int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We only want to learn to recogize setosa\n",
    "y = 1*(y == 0) # y gets 1s for setosa and 0s for versicolor or virginica (only run this cell once or restart kernel!)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[119 134  72  52 131  92   8  50  64  89  23 149  57  94  32 112  18  27\n",
      "  59 147 113 140 141 121  51  55  81 125 106  15 130   9 137   5  22  34\n",
      " 122  43  38  62  85  14   1 126  79 107  20  73 102 117 138  54  24  90\n",
      "  82 116  39  68 103  70  87   6  25  61 115  44   4 109  28 118  86  17\n",
      "  16 128 132  10 136  91  96   0  13  84 123 105  63  26  19  78  74 124\n",
      "  29 110 104  41  49  47 135 148 100 108 143  40 120  77  99  37  76 139\n",
      "  36  95  67  21  83 144  31 145  66 146  69  80  88  48 111  65  93 129\n",
      "  33  75 114 133  97   2  98  53  58   3  11  12 127  45  46  71  42 101\n",
      "   7  30  35  60  56 142]\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import permutation\n",
    "perm = permutation(len(X))\n",
    "print(perm) # new random ordering both for X inputs and y outputs\n",
    "X = X[perm] # 150x4 permuted numpy.ndarray (inputs)\n",
    "y = y[perm] # 150 permuted numpy.ndarray (outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "(120, 4)\n",
      "(120,)\n",
      "(30, 4)\n",
      "(30,)\n"
     ]
    }
   ],
   "source": [
    "count = X.shape[0]           # 150\n",
    "print(count)\n",
    "\n",
    "# Split X and y into 80% training and 20% testing data sets\n",
    "\n",
    "train_X = X[:int(count*0.8)]\n",
    "print(train_X.shape)         # (120, 4) train_X -> training inputs\n",
    "train_y = y[:int(count*0.8)]\n",
    "print(train_y.shape)         # (120,)   train_y -> training output\n",
    "\n",
    "test_X = X[int(count*0.8):]\n",
    "print(test_X.shape)          # (30, 4)  test_X  -> testing input labels\n",
    "test_y = y[int(count*0.8):]\n",
    "print(test_y.shape)          # (30,)    test_y  -> testing output labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0.]\n",
      "* num_no_zero_errors:  7\n",
      "* num_no_zero_errors:  0\n",
      "[ 0.01   0.015  0.049 -0.07  -0.032]\n"
     ]
    }
   ],
   "source": [
    "# Do some training\n",
    "\n",
    "num_inputs = test_X.shape[1] # 4 input columns\n",
    "weights = np.zeros(num_inputs + 1) # weights for each of the 4 inputs plus one for the bias term\n",
    "\n",
    "perceptron = Perceptron(num_inputs)\n",
    "perceptron.train(train_X, train_y) # train on 80% training input and output data\n",
    "print(perceptron.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  0.0  -> actual:  0  -> correct:  True\n",
      "predicted:  1.0  -> actual:  1  -> correct:  True\n",
      "predicted:  0.0  -> actual:  0  -> correct:  True\n",
      "predicted:  0.0  -> actual:  0  -> correct:  True\n",
      "predicted:  0.0  -> actual:  0  -> correct:  True\n",
      "predicted:  0.0  -> actual:  0  -> correct:  True\n",
      "predicted:  1.0  -> actual:  1  -> correct:  True\n",
      "predicted:  0.0  -> actual:  0  -> correct:  True\n",
      "predicted:  0.0  -> actual:  0  -> correct:  True\n",
      "predicted:  0.0  -> actual:  0  -> correct:  True\n",
      "predicted:  0.0  -> actual:  0  -> correct:  True\n",
      "predicted:  1.0  -> actual:  1  -> correct:  True\n",
      "predicted:  0.0  -> actual:  0  -> correct:  True\n",
      "predicted:  0.0  -> actual:  0  -> correct:  True\n",
      "predicted:  0.0  -> actual:  0  -> correct:  True\n",
      "predicted:  1.0  -> actual:  1  -> correct:  True\n",
      "predicted:  1.0  -> actual:  1  -> correct:  True\n",
      "predicted:  1.0  -> actual:  1  -> correct:  True\n",
      "predicted:  0.0  -> actual:  0  -> correct:  True\n",
      "predicted:  1.0  -> actual:  1  -> correct:  True\n",
      "predicted:  1.0  -> actual:  1  -> correct:  True\n",
      "predicted:  0.0  -> actual:  0  -> correct:  True\n",
      "predicted:  1.0  -> actual:  1  -> correct:  True\n",
      "predicted:  0.0  -> actual:  0  -> correct:  True\n",
      "predicted:  1.0  -> actual:  1  -> correct:  True\n",
      "predicted:  1.0  -> actual:  1  -> correct:  True\n",
      "predicted:  1.0  -> actual:  1  -> correct:  True\n",
      "predicted:  0.0  -> actual:  0  -> correct:  True\n",
      "predicted:  0.0  -> actual:  0  -> correct:  True\n",
      "predicted:  0.0  -> actual:  0  -> correct:  True\n"
     ]
    }
   ],
   "source": [
    "# Do some predicting\n",
    "\n",
    "for _X, _y in zip(test_X, test_y):\n",
    "    prediction = perceptron.predict(_X)\n",
    "    actual = _y\n",
    "    correct = prediction == actual\n",
    "    print(\"predicted: \", prediction, \" -> actual: \", actual, \" -> correct: \", correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  0.0  -> actual:  0  -> correct:  True\n",
      "predicted:  0.0  -> actual:  1  -> correct:  False\n",
      "predicted:  0.0  -> actual:  0  -> correct:  True\n",
      "predicted:  0.0  -> actual:  0  -> correct:  True\n",
      "predicted:  0.0  -> actual:  0  -> correct:  True\n",
      "predicted:  0.0  -> actual:  0  -> correct:  True\n",
      "predicted:  0.0  -> actual:  1  -> correct:  False\n",
      "predicted:  0.0  -> actual:  0  -> correct:  True\n",
      "predicted:  1.0  -> actual:  0  -> correct:  False\n",
      "predicted:  0.0  -> actual:  0  -> correct:  True\n",
      "predicted:  0.0  -> actual:  0  -> correct:  True\n",
      "predicted:  1.0  -> actual:  1  -> correct:  True\n",
      "predicted:  0.0  -> actual:  0  -> correct:  True\n",
      "predicted:  0.0  -> actual:  0  -> correct:  True\n",
      "predicted:  0.0  -> actual:  0  -> correct:  True\n",
      "predicted:  1.0  -> actual:  1  -> correct:  True\n",
      "predicted:  1.0  -> actual:  1  -> correct:  True\n",
      "predicted:  1.0  -> actual:  1  -> correct:  True\n",
      "predicted:  0.0  -> actual:  0  -> correct:  True\n",
      "predicted:  1.0  -> actual:  1  -> correct:  True\n",
      "predicted:  1.0  -> actual:  1  -> correct:  True\n",
      "predicted:  0.0  -> actual:  0  -> correct:  True\n",
      "predicted:  1.0  -> actual:  1  -> correct:  True\n",
      "predicted:  0.0  -> actual:  0  -> correct:  True\n",
      "predicted:  1.0  -> actual:  1  -> correct:  True\n",
      "predicted:  1.0  -> actual:  1  -> correct:  True\n",
      "predicted:  1.0  -> actual:  1  -> correct:  True\n",
      "predicted:  0.0  -> actual:  0  -> correct:  True\n",
      "predicted:  0.0  -> actual:  0  -> correct:  True\n",
      "predicted:  0.0  -> actual:  0  -> correct:  True\n"
     ]
    }
   ],
   "source": [
    "# force errors in classification with bad data in first ten rows and see what happens to prediction correctness\n",
    "\n",
    "test_X[0] = 10*np.random.rand(4) \n",
    "test_X[1] = 10*np.random.rand(4)\n",
    "test_X[2] = 10*np.random.rand(4)\n",
    "test_X[3] = 10*np.random.rand(4)\n",
    "test_X[4] = 10*np.random.rand(4)\n",
    "test_X[5] = 10*np.random.rand(4)\n",
    "test_X[6] = 10*np.random.rand(4)\n",
    "test_X[7] = 10*np.random.rand(4)\n",
    "test_X[8] = 10*np.random.rand(4)\n",
    "test_X[9] = 10*np.random.rand(4)\n",
    "\n",
    "for _X, _y in zip(test_X, test_y):\n",
    "    prediction = perceptron.predict(_X)\n",
    "    actual = _y\n",
    "    correct = prediction == actual\n",
    "    print(\"predicted: \", prediction, \" -> actual: \", actual, \" -> correct: \", correct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
